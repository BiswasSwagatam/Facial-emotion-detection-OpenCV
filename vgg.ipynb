{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 24256 images belonging to 5 classes.\n",
      "Found 3006 images belonging to 5 classes.\n",
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_33 (Conv2D)           (None, 48, 48, 32)        320       \n",
      "_________________________________________________________________\n",
      "activation_45 (Activation)   (None, 48, 48, 32)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_41 (Batc (None, 48, 48, 32)        128       \n",
      "_________________________________________________________________\n",
      "conv2d_34 (Conv2D)           (None, 48, 48, 32)        9248      \n",
      "_________________________________________________________________\n",
      "activation_46 (Activation)   (None, 48, 48, 32)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_42 (Batc (None, 48, 48, 32)        128       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_17 (MaxPooling (None, 24, 24, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_25 (Dropout)         (None, 24, 24, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_35 (Conv2D)           (None, 24, 24, 32)        9248      \n",
      "_________________________________________________________________\n",
      "activation_47 (Activation)   (None, 24, 24, 32)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_43 (Batc (None, 24, 24, 32)        128       \n",
      "_________________________________________________________________\n",
      "conv2d_36 (Conv2D)           (None, 24, 24, 32)        9248      \n",
      "_________________________________________________________________\n",
      "activation_48 (Activation)   (None, 24, 24, 32)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_44 (Batc (None, 24, 24, 32)        128       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_18 (MaxPooling (None, 12, 12, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_26 (Dropout)         (None, 12, 12, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_37 (Conv2D)           (None, 12, 12, 128)       36992     \n",
      "_________________________________________________________________\n",
      "activation_49 (Activation)   (None, 12, 12, 128)       0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_45 (Batc (None, 12, 12, 128)       512       \n",
      "_________________________________________________________________\n",
      "conv2d_38 (Conv2D)           (None, 12, 12, 128)       147584    \n",
      "_________________________________________________________________\n",
      "activation_50 (Activation)   (None, 12, 12, 128)       0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_46 (Batc (None, 12, 12, 128)       512       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_19 (MaxPooling (None, 6, 6, 128)         0         \n",
      "_________________________________________________________________\n",
      "dropout_27 (Dropout)         (None, 6, 6, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_39 (Conv2D)           (None, 6, 6, 256)         295168    \n",
      "_________________________________________________________________\n",
      "activation_51 (Activation)   (None, 6, 6, 256)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_47 (Batc (None, 6, 6, 256)         1024      \n",
      "_________________________________________________________________\n",
      "conv2d_40 (Conv2D)           (None, 6, 6, 256)         590080    \n",
      "_________________________________________________________________\n",
      "activation_52 (Activation)   (None, 6, 6, 256)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_48 (Batc (None, 6, 6, 256)         1024      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_20 (MaxPooling (None, 3, 3, 256)         0         \n",
      "_________________________________________________________________\n",
      "dropout_28 (Dropout)         (None, 3, 3, 256)         0         \n",
      "_________________________________________________________________\n",
      "flatten_5 (Flatten)          (None, 2304)              0         \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 64)                147520    \n",
      "_________________________________________________________________\n",
      "activation_53 (Activation)   (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_49 (Batc (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "dropout_29 (Dropout)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "activation_54 (Activation)   (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_50 (Batc (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "dropout_30 (Dropout)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 5)                 325       \n",
      "_________________________________________________________________\n",
      "activation_55 (Activation)   (None, 5)                 0         \n",
      "=================================================================\n",
      "Total params: 1,253,989\n",
      "Trainable params: 1,251,941\n",
      "Non-trainable params: 2,048\n",
      "_________________________________________________________________\n",
      "None\n",
      "WARNING:tensorflow:From C:\\Users\\lenovo\\Anaconda3\\lib\\site-packages\\keras\\optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\lenovo\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\ops\\math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "Epoch 1/25\n",
      "758/758 [==============================] - 435s 573ms/step - loss: 1.6858 - acc: 0.2656 - val_loss: 1.5706 - val_acc: 0.2923\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.57056, saving model to emotion_vgg.h5\n",
      "Epoch 2/25\n",
      "758/758 [==============================] - 71s 93ms/step - loss: 1.5578 - acc: 0.2938 - val_loss: 1.5388 - val_acc: 0.3043\n",
      "\n",
      "Epoch 00002: val_loss improved from 1.57056 to 1.53881, saving model to emotion_vgg.h5\n",
      "Epoch 3/25\n",
      "758/758 [==============================] - 71s 93ms/step - loss: 1.5250 - acc: 0.3185 - val_loss: 1.4933 - val_acc: 0.3436\n",
      "\n",
      "Epoch 00003: val_loss improved from 1.53881 to 1.49330, saving model to emotion_vgg.h5\n",
      "Epoch 4/25\n",
      "758/758 [==============================] - 71s 94ms/step - loss: 1.4863 - acc: 0.3417 - val_loss: 1.6896 - val_acc: 0.2471\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 1.49330\n",
      "Epoch 5/25\n",
      "758/758 [==============================] - 71s 94ms/step - loss: 1.4194 - acc: 0.3851 - val_loss: 1.3192 - val_acc: 0.4529- \n",
      "\n",
      "Epoch 00005: val_loss improved from 1.49330 to 1.31918, saving model to emotion_vgg.h5\n",
      "Epoch 6/25\n",
      "758/758 [==============================] - 71s 94ms/step - loss: 1.3411 - acc: 0.4330 - val_loss: 1.3436 - val_acc: 0.4603\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 1.31918\n",
      "Epoch 7/25\n",
      "758/758 [==============================] - 71s 94ms/step - loss: 1.2832 - acc: 0.4702 - val_loss: 1.3176 - val_acc: 0.5313\n",
      "\n",
      "Epoch 00007: val_loss improved from 1.31918 to 1.31758, saving model to emotion_vgg.h5\n",
      "Epoch 8/25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "758/758 [==============================] - 71s 94ms/step - loss: 1.2398 - acc: 0.4873 - val_loss: 1.2919 - val_acc: 0.4963oss: 1.2397 - acc: 0 - ETA: 0s - loss: 1.2400 - a\n",
      "\n",
      "Epoch 00008: val_loss improved from 1.31758 to 1.29185, saving model to emotion_vgg.h5\n",
      "Epoch 9/25\n",
      "758/758 [==============================] - 71s 94ms/step - loss: 1.2039 - acc: 0.5107 - val_loss: 1.5044 - val_acc: 0.5158TA:\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 1.29185\n",
      "Epoch 10/25\n",
      "758/758 [==============================] - 71s 94ms/step - loss: 1.1844 - acc: 0.5188 - val_loss: 1.3687 - val_acc: 0.54241s - loss: \n",
      "\n",
      "Epoch 00010: val_loss did not improve from 1.29185\n",
      "Epoch 11/25\n",
      "758/758 [==============================] - 73s 96ms/step - loss: 1.1639 - acc: 0.5282 - val_loss: 1.3038 - val_acc: 0.5256\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 1.29185\n",
      "\n",
      "Epoch 00011: ReduceLROnPlateau reducing learning rate to 0.0006000000052154065.\n",
      "Epoch 12/25\n",
      "758/758 [==============================] - 73s 96ms/step - loss: 1.1179 - acc: 0.5550 - val_loss: 1.2653 - val_acc: 0.5656\n",
      "\n",
      "Epoch 00012: val_loss improved from 1.29185 to 1.26532, saving model to emotion_vgg.h5\n",
      "Epoch 13/25\n",
      "758/758 [==============================] - 73s 96ms/step - loss: 1.1015 - acc: 0.5587 - val_loss: 1.2234 - val_acc: 0.5921\n",
      "\n",
      "Epoch 00013: val_loss improved from 1.26532 to 1.22338, saving model to emotion_vgg.h5\n",
      "Epoch 14/25\n",
      "758/758 [==============================] - 73s 96ms/step - loss: 1.0834 - acc: 0.5698 - val_loss: 1.2203 - val_acc: 0.5639\n",
      "\n",
      "Epoch 00014: val_loss improved from 1.22338 to 1.22025, saving model to emotion_vgg.h5\n",
      "Epoch 15/25\n",
      "758/758 [==============================] - 73s 97ms/step - loss: 1.0799 - acc: 0.5690 - val_loss: 1.1892 - val_acc: 0.5928: 0 - ETA: 0s - loss: 1.0799 - acc: \n",
      "\n",
      "Epoch 00015: val_loss improved from 1.22025 to 1.18923, saving model to emotion_vgg.h5\n",
      "Epoch 16/25\n",
      "758/758 [==============================] - 73s 97ms/step - loss: 1.0583 - acc: 0.5809 - val_loss: 1.2700 - val_acc: 0.5824\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 1.18923\n",
      "Epoch 17/25\n",
      "758/758 [==============================] - 74s 97ms/step - loss: 1.0563 - acc: 0.5813 - val_loss: 1.2665 - val_acc: 0.5831\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 1.18923\n",
      "Epoch 18/25\n",
      "758/758 [==============================] - 74s 97ms/step - loss: 1.0430 - acc: 0.5909 - val_loss: 1.2519 - val_acc: 0.5975\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 1.18923\n",
      "\n",
      "Epoch 00018: ReduceLROnPlateau reducing learning rate to 0.00012000000569969416.\n",
      "Epoch 19/25\n",
      "758/758 [==============================] - 74s 98ms/step - loss: 1.0427 - acc: 0.5825 - val_loss: 1.2269 - val_acc: 0.6009\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 1.18923\n",
      "Epoch 20/25\n",
      "758/758 [==============================] - 74s 97ms/step - loss: 1.0361 - acc: 0.5899 - val_loss: 1.2247 - val_acc: 0.5915\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 1.18923\n",
      "Epoch 21/25\n",
      "758/758 [==============================] - 74s 98ms/step - loss: 1.0364 - acc: 0.5925 - val_loss: 1.1975 - val_acc: 0.6049.0420  - ETA: 8s - loss:  - ETA: 6s - loss: 1. - ETA: 5s - loss: 1.039\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 1.18923\n",
      "\n",
      "Epoch 00021: ReduceLROnPlateau reducing learning rate to 2.4000000848900527e-05.\n",
      "Epoch 22/25\n",
      "758/758 [==============================] - 74s 98ms/step - loss: 1.0379 - acc: 0.5865 - val_loss: 1.2447 - val_acc: 0.5948\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 1.18923\n",
      "Epoch 23/25\n",
      "758/758 [==============================] - 74s 98ms/step - loss: 1.0302 - acc: 0.5947 - val_loss: 1.2147 - val_acc: 0.5982c: 0. - ETA: 5s -  - ETA: \n",
      "\n",
      "Epoch 00023: val_loss did not improve from 1.18923\n",
      "Epoch 24/25\n",
      "758/758 [==============================] - 74s 98ms/step - loss: 1.0267 - acc: 0.5945 - val_loss: 1.1921 - val_acc: 0.6032ss: 1.0 - ETA: 3s - ETA: 0s - loss: 1.0271 - ac\n",
      "Restoring model weights from the end of the best epoch\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 1.18923\n",
      "\n",
      "Epoch 00024: ReduceLROnPlateau reducing learning rate to 4.800000169780105e-06.\n",
      "Epoch 00024: early stopping\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import keras\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense,Dropout,Activation,Flatten,BatchNormalization\n",
    "from keras.layers import Conv2D,MaxPooling2D\n",
    "import os\n",
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_v2_behavior()\n",
    "\n",
    "num_classes = 5\n",
    "img_rows,img_cols = 48,48\n",
    "batch_size = 32\n",
    "\n",
    "train_data_dir = 'C:/Users/lenovo/Desktop/my code/my work/emoition/fer2013/train'\n",
    "validation_data_dir = 'C:/Users/lenovo/Desktop/my code/my work/emoition/fer2013/validation'\n",
    "\n",
    "train_datagen = ImageDataGenerator(rescale=1./255,\n",
    "                                    rotation_range=30,\n",
    "                                    shear_range=0.3,\n",
    "                                    zoom_range=0.3,\n",
    "                                    width_shift_range=0.4,\n",
    "                                    height_shift_range=0.4,\n",
    "                                    horizontal_flip=True,\n",
    "                                    fill_mode='nearest')\n",
    "\n",
    "validation_datagen = ImageDataGenerator(rescale=1./255)  \n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(train_data_dir,\n",
    "                                                    color_mode='grayscale',\n",
    "                                                    target_size=(img_rows,img_cols),\n",
    "                                                    batch_size=batch_size,\n",
    "                                                    class_mode='categorical',\n",
    "                                                    shuffle=True)\n",
    "\n",
    "validation_generator = validation_datagen.flow_from_directory(validation_data_dir,\n",
    "                                                            color_mode='grayscale',\n",
    "                                                            target_size=(img_rows,img_cols),\n",
    "                                                            batch_size=batch_size,\n",
    "                                                            class_mode='categorical',\n",
    "                                                            shuffle=True) \n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "#block 1\n",
    "\n",
    "model.add(Conv2D(32,(3,3),padding='same',kernel_initializer='he_normal',input_shape=(img_rows,img_cols,1)))\n",
    "model.add(Activation('elu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(32,(3,3),padding='same',kernel_initializer='he_normal',input_shape=(img_rows,img_cols,1)))\n",
    "model.add(Activation('elu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "#block 2\n",
    "\n",
    "model.add(Conv2D(32,(3,3),padding='same',kernel_initializer='he_normal'))\n",
    "model.add(Activation('elu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(32,(3,3),padding='same',kernel_initializer='he_normal'))\n",
    "model.add(Activation('elu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "#block 3\n",
    "\n",
    "model.add(Conv2D(128,(3,3),padding='same',kernel_initializer='he_normal'))\n",
    "model.add(Activation('elu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(128,(3,3),padding='same',kernel_initializer='he_normal'))\n",
    "model.add(Activation('elu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "#block 4 \n",
    "\n",
    "model.add(Conv2D(256,(3,3),padding='same',kernel_initializer='he_normal'))\n",
    "model.add(Activation('elu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(256,(3,3),padding='same',kernel_initializer='he_normal'))\n",
    "model.add(Activation('elu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "#block 5\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64,kernel_initializer='he_normal'))\n",
    "model.add(Activation('elu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "#block 6\n",
    "model.add(Dense(64,kernel_initializer='he_normal'))\n",
    "model.add(Activation('elu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "#block 7\n",
    "model.add(Dense(num_classes,kernel_initializer='he_normal'))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "print(model.summary())\n",
    "\n",
    "from keras.optimizers import RMSprop, SGD, Adam\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
    "\n",
    "checkpoint = ModelCheckpoint('emotion_vgg.h5',\n",
    "                              monitor='val_loss',\n",
    "                              mode='min',\n",
    "                              save_best_only=True,\n",
    "                              verbose=1)\n",
    "\n",
    "earlystop = EarlyStopping(monitor='val_loss',\n",
    "                      min_delta=0,\n",
    "                      patience=9,\n",
    "                      verbose=1,\n",
    "                      restore_best_weights=True)\n",
    "\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss',\n",
    "                              factor=0.2,\n",
    "                              patience=3,\n",
    "                              verbose=1,\n",
    "                              min_delta=0.0001)\n",
    "\n",
    "callbacks = [earlystop,checkpoint,reduce_lr]\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=Adam(lr=0.003),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "nb_train_samples = 24256\n",
    "nb_validation_samples = 3006\n",
    "epochs = 25\n",
    "\n",
    "history = model.fit_generator(train_generator,\n",
    "                              steps_per_epoch=nb_train_samples//batch_size,\n",
    "                              epochs=epochs,\n",
    "                              callbacks=callbacks,\n",
    "                              validation_data=validation_generator,\n",
    "                              validation_steps=nb_validation_samples//batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
